% Title:    A LaTeX Template For Responses To a Referees' Reports
% Author:   Petr Zemek <s3rvac@gmail.com>
% Homepage: https://blog.petrzemek.net/2016/07/17/latex-template-for-responses-to-referees-reports/
% License:  CC BY 4.0 (https://creativecommons.org/licenses/by/4.0/)
\documentclass[10pt]{article}

\newcommand{\pg}[1]{p.\ #1}
\newcommand{\weight}[1]{w\textsubscript{#1}}
\newcommand{\nmax}{n_{\text{max}}}
% Allow Unicode input (alternatively, you can use XeLaTeX or LuaLaTeX)
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{microtype,xparse,tcolorbox}
\usepackage[margin=1.25in]{geometry}
\newenvironment{reviewer-comment }{}{}
\tcbuselibrary{skins}
\tcolorboxenvironment{reviewer-comment }{empty,
  left = 1em, top = 1ex, bottom = 1ex,
  borderline west = {2pt} {0pt} {black!20},
}
\ExplSyntaxOn
\NewDocumentEnvironment {response} { +m O{black!20} } {
  \IfValueT {#1} {
    \begin{reviewer-comment~}
      \setlength\parindent{2em}
      \noindent
      \ttfamily #1
    \end{reviewer-comment~}
  }
  \par\noindent\ignorespaces
} { \bigskip\par }

\NewDocumentCommand \Reviewer { m } {
  \section*{Comments~by~Reviewer~#1}
}
\ExplSyntaxOff
\AtBeginDocument{\maketitle\thispagestyle{empty}\noindent}

% You can get probably get rid of these definitions:
\newcommand\meta[1]{$\langle\hbox{#1}\rangle$}
\newcommand\PaperTitle[1]{``\textit{#1}''}

\title{Statement on the Revision of \meta{M118490} \\
  Based on the Referees' Report}
\author{Kevin W. Aiton \and Tobin A. Driscoll}
\date{\today}

\begin{document}
We'd like to thank the referees for their comments, which were both helpful and thoughtful. This statement concerns our revision of the \meta{M118490} paper,
entitled \textit{An adaptive partition of unity method for multivariate Chebyshev polynomial approximations}, based on the referees' report.

\Reviewer{\#1}
\begin{enumerate}
\item \begin{response}{  I hate it when a referee says a manuscript must cite his own work, but it is very strange that this paper
talks so much about isotropy yet doesn't mention my 2017
SIAM Review paper \textit{Cubature, approximation, and isotropy
in the hypercube}, which, so far as I know, is the only
general work ever published explicitly focussing on this
issue. (It encompasses both the low-rank and the sparse
grid settings.) It also surprises me that the authors did
not include as one of their 2D tests the "square peg" and
"tilted peg" examples from that paper, which are available
in the Chebfun2 gallery of functions. }
We included the square and tilted peg examples in 2D. This can be seen in Table 4.1. We added a reference to the peg examples on line 247. The paper \textit{Cubature, approximation, and isotropy in the hypercube} is referenced on line 43 for the isotropy properties of the approximations and line 247 to reference the peg examples.
\end{response}

\item \begin{response}{ I don't think the authors discuss the choice of $N$, though I notice $N$=129 in the 2D table and $N$=65 in the
3D table. Should remarks be made about what values are
appropriate? Is there a tradeoff that makes 17 too small
and 513 too large? }
While we did explore the use of different $N$, we were not able to find a consistent pattern. In 3D, the choices become more restricted due to memory constraints.
\end{response}

\item \begin{response}{ Could some sentences or a theorem be added to tell readers the basic properties of the partition of unity?
I believe it is $C^{\infty}$ and takes the constant value of
1 in part of (not all of) each zone. It would help to be
told such things. How about presenting a larger version
of a figure along the lines of Figure 4.1(b), which one
could talk through to illustrate how some parts of the
region have a single Chebyshev representation whereas
other use blends of several?}
On lines 155-158 we elaborate on why the Shepard's weights form a partition of unity. We also explain some of the properties of the partition of unity as well as why overlap is needed for the functions to be smooth. On line 166 we explain the properties of the partition of unity approximation itself i.e. that it is smooth, and does not require matching.

On lines 166-170, we use the referee's suggestion of presenting a larger version of Figure 4.1(b) and explain how the partition of unity approximation consists of a single polynomial in the interior and a blending of polynomials in the overlap.
\end{response}

\item \begin{response}{In section 3.3, on differentiation, one of the
two sums in the mathematical derivative is rather
startlingly discarded. An explanation is given of why
"we feel justified [in] ignoring this contribution",
but I am uneasy about whether this is really justified.
If the contribution in question is truly small, then the
authors should be able to confirm that with negligible
addition of length to the paper by reporting measured
accuracy of derivatives in some of their 2D and 3D
experiments.}
We added Theorem 3.1 on line 208 to address the accuracy of the derivatives.
\end{response}

\item \begin{response}{Related to both of the items above, global smoothness is the most unusual feature of these representations, the very heart of the POU enterprise. A little more discussion
of its significance, and of where in this algorithm it is
used, might be welcome.}
On line 162, we add a statement of how despite having an approximation composed of separate polynomials from a partitioned domain, we still have a smooth approximation while avoiding explicit global matching constraints.
\end{response}

\item \begin{response}{The numerical experiments of this manuscript, I am afraid, have not been carefully reported. When I try
to duplicate them, not everything goes as expected.
A small item: should the exponent -3 in the 7th example
of Table 4.1 and the 3rd example of Table 4.2 be +3?
More seriously: though it is claimed that a tolerance
$10^{-12}$ is used in the Chebfun tests, I suspect that some or
all of the experiments were actually run with the tighter
default tolerance $2^{-52}$. This makes the tables incorrect
and introduces a systematic bias in the comparisons.
For example, if I run the first 2D example of Table 4.1
with standard tolerance, I get rank 30 and time 2.8, as the
table reports. But if I set chebfun2eps $10^{-12}$, the rank
reduces to 20 and the time is cut to 0.8. Similarly, if
I run the penultimate (cosh) 3D example of Table 4.2 with
standard tolerance I get [Tucker] rank 93 and build time 80
seconds, as the table reports. But if I set chebfun3eps
$10^{-12}$, the rank reduces to 70 and the time to 20 seconds.
I regret to say that I believe the authors need to rerun
every experiment in this paper to make sure their results
are reported correctly.}

The exponents for the 7th example in Table 4.2 should be $-3$, while the third example in 4.2 should be $-4$; this is the corner peak example from the Genz test package. This mistake is corrected in the table. We redid the tests so the tree based methods used the same relative tolerance as Chebfun (i.e. the tolerance dictated in the preferences). This can be seen in Table 4.1 and Table 4.2. The description of the 2D results on lines 245-256 are updated to reflect this. On lines 273-282 the description of the 3D results are similarly updated.

\end{response}

\item \begin{response}{Quite a different matter is the following
conceptual problem. The authors argue that their
subdivisions are efficient, and in particular, are
much faster than Chebfun2/3 for functions not aligned
with the axes. Unfortunately, I think some of what their
comparisons show is not the speed of their method so much
as the slowness of Chebfun -- specifically, the time
Chebfun may waste trying to compress a function to low
rank. In 3D, one can check this by comparing Chebfun3
against Chebfun3t, which constructs a vanilla tensor product
approximation without making any attempts with low rank.
Take the 3D cosh example just mentioned above. If this is
run in Chebfun3t rather than Chebfun3, the build time with
tolerance $10^{-12}$ shrinks from 20 to 3.4 seconds. This is
still slower than the 0.7 seconds reported in Table 4.2 for
the tree algorithm, but no longer dramatically slower.
I think as a minimum the authors need to modify their
comments about the speed of their method.}

 It's clearly true that sometimes Chebfun3 will 'waste' time trying to compress a resistant function. As far as we know, though, there's no easy way to know in advance or through simple heuristics when that will be the case (else why doesn't Chebfun3 do that?). From the standpoint of seeking a fully automatic and adaptive algorithm, we think that this is a genuine and significant characteristic of the approach. 

A clear theme throughout our results and discussions is that Chebfun2/3 is sensitive to the numerical rank of the targeted function. We have attempted to reinforce those statements further in our revisions. However, we feel it's valuable to base the experimental comparisons on software as presented to the public. Similarly, we have taken our test functions from other prominent sources without regard to how they might make either algorithm appear. (Indeed, a majority of our examples happen to have very low rank, already putting Chebfun in a rather favorable light.) Once we start using additional knowledge to help out one method or the other, we start down a slippery slope and may obfuscate more than we illuminate.
\end{response}

\end{enumerate}

\end{document}